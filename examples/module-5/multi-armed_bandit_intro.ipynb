{"cells":[{"cell_type":"markdown","source":"# Multi-armed bandits","metadata":{"cell_id":"00000-02855f12-bbe9-4c74-b198-cc155038370a","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"[Source](https://stackabuse.com/introduction-to-reinforcement-learning-with-python/)","metadata":{"cell_id":"00001-eb874d6b-09dc-4bd9-923e-b7616244f3bc","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00002-9fb00d47-c892-452f-924b-7b248bba33ba","deepnote_cell_type":"code"},"source":"import numpy as np","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00003-7a9300ad-aac5-4b27-adc2-7e3f50ab493c","deepnote_cell_type":"code"},"source":"# Number of bandits\nk = 3\n\n# Epsilon value for exploration\neps = 0.1\n\n# True probability of winning for each bandit\np_bandits = [0.45, 0.40, 0.80]\n","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00004-8bad1b80-65c6-403b-84d2-a217bc08fea0","deepnote_cell_type":"code"},"source":"# We use mean reward as the goodness value of an action\n# Q is the vector of goodness values for the k bandits\nQ = [0 for _ in range(k)]\nQ","outputs":[{"data":{"text/plain":"[0, 0, 0]"},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00005-e29f5b4b-c8d2-4766-9853-fa8617abe41a","deepnote_cell_type":"code"},"source":"# This is to keep track of the number of times we try each bandit\nN = [0 for _ in range(k)]\nN","outputs":[{"data":{"text/plain":"[0, 0, 0]"},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00006-1e24a8a3-5b87-4e6b-9b88-c38022c451cd","deepnote_cell_type":"code"},"source":"\ndef pull(a):\n    \"\"\"Pull arm of bandit number a and return 1 if win, \n    else return 0.\"\"\"\n    if np.random.rand() < p_bandits[a]:\n        return 1 #win\n    else:\n        return 0 #loss\n\nwhile True: #Press the stop button after a few seconds\n    # Select action\n    if np.random.rand() > eps:\n        # Take greedy action most of the time\n        a = np.argmax(Q)\n    else:\n        # Take random action with probability eps\n        a = np.random.randint(0, k)\n    \n    # Collect reward\n    reward = pull(a)\n    \n    # Incremental average\n    N[a] += 1\n    Q[a] += 1/N[a] * (reward - Q[a])","outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-8-d67e075c622f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Select action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Take greedy action most of the time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00007-43de1ded-29aa-4da9-8715-7201c1e7e4b6","deepnote_cell_type":"code"},"source":"Q","outputs":[{"data":{"text/plain":"[0.45013061030633933, 0.40073420569601265, 0.8004163998795629]"},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00008-bf3ecdb7-cf05-4c68-bbae-39aa299935de","deepnote_cell_type":"code"},"source":"N","outputs":[{"data":{"text/plain":"[16844, 16889, 471662]"},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"execution_count":null},{"cell_type":"code","metadata":{"cell_id":"00009-6ab926c0-db0b-4724-9470-c1e2391d66c1","deepnote_cell_type":"code"},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"deepnote_notebook_id":"f92e5837-bda8-4d21-99b8-90150d5e5706","deepnote_execution_queue":[]}}